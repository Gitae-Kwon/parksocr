# app.py

import io
import re
import streamlit as st
import pandas as pd
from PIL import Image
from google.cloud import vision
from google.oauth2 import service_account

# â”€â”€â”€ 1) ì¸ì¦ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
service_account_info = st.secrets["gcp_service_account"]
creds  = service_account.Credentials.from_service_account_info(service_account_info)
client = vision.ImageAnnotatorClient(credentials=creds)

# â”€â”€â”€ 2) ì „ì²´ OCR í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ocr_google_vision(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="JPEG")
    resp = client.document_text_detection(image=vision.Image(content=buf.getvalue()))
    if resp.error.message:
        raise RuntimeError(resp.error.message)
    return resp.full_text_annotation.text

# â”€â”€â”€ 3) HEADER í•„ë“œ íŒŒì‹±(ì´ë¦„Â·ì „ë²ˆÂ·ìƒë…„Â·ê²°í•©Â·ì£¼ì†Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# multiline ëª¨ë“œ, ì¤„ ì‹œì‘(^)Â·ì¤„ ë($) ê°•ì œ
HEADER_PATTERNS = {
    "ì´ë¦„": r"(?m)^ì´ë¦„[:ï¼š]\s*(.+)$",
    "ì „ë²ˆ": r"(?m)^ì „ë²ˆ[:ï¼š]\s*([\d\s\-]+)$",
    "ìƒë…„": r"(?m)^ìƒë…„[:ï¼š]\s*(\d{6,8})$",
    "ê²°í•©": r"(?m)^ê²°í•©[:ï¼š]\s*(.+)$",
    "ì£¼ì†Œ": r"(?m)^ì£¼ì†Œ[:ï¼š]\s*(.+)$",
}

def parse_header(text: str) -> dict:
    data = {}
    for field, pat in HEADER_PATTERNS.items():
        vals = re.findall(pat, text)
        # "ì´ë¦„" ê°™ì€ ë ˆì´ë¸”ë§Œ ì¡íŒ ê²½ìš° ì œê±°
        vals = [v.strip() for v in vals if v.strip() and v.strip() != field]
        data[field] = vals[-1] if vals else None
    return data

# â”€â”€â”€ 4) ê¸°íƒ€ í•„ë“œ íŒŒì‹±(ì¸í„°ë„·Â·TVÂ·ìŠ¤ë§ˆíŠ¸í™ˆÂ·ê³ ê°í¬ë§ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OTHER_PATTERNS = {
    "U+ ì¸í„°ë„·":      r"U\+\s*ì¸í„°ë„·[:\s]*([0-9]+)",
    "ì¸í„°ë„·_ìš”ê¸ˆì œ":   r"ìš”ê¸ˆì œ[:\s]*([^\n]+)",
    "ì¸í„°ë„·_ì•½ì •ì‹œì‘":  r"ì•½ì •ê¸°ê°„[^(]*\((\d{4}-\d{2}-\d{2})\)",
    "ì¸í„°ë„·_ì•½ì •ì¢…ë£Œ":  r"ì•½ì •ê¸°ê°„[^(]*\(\d{4}-\d{2}-\d{2}~(\d{4}-\d{2}-\d{2})\)",
    "ì¸í„°ë„·_ë‹¨ë§":    r"ë‹¨ë§[:\s]*([^\n]+)",

    "U+ TV (ì£¼)":     r"U\+\s*TV\s*\(ì£¼\)[:\s]*([0-9]+)",
    "TVì£¼_ìš”ê¸ˆì œ":     r"TV\s*\(ì£¼\)[\s\S]*?ìš”ê¸ˆì œ[:\s]*([^\n]+)",
    "TVì£¼_ì•½ì •ì‹œì‘":   r"TV\s*\(ì£¼\)[\s\S]*?ì•½ì •ê¸°ê°„[^(]*\((\d{4}-\d{2}-\d{2})\)",
    "TVì£¼_ì•½ì •ì¢…ë£Œ":   r"TV\s*\(ì£¼\)[\s\S]*?ì•½ì •ê¸°ê°„[^(]*\(\d{4}-\d{2}-\d{2}~(\d{4}-\d{2}-\d{2})\)",
    "TVì£¼_ë‹¨ë§":     r"TV\s*\(ì£¼\)[\s\S]*?ë‹¨ë§[:\s]*([^\n]+)",

    "U+ TV (ë¶€)":     r"U\+\s*TV\s*\(ë¶€\)[:\s]*([0-9]+)",
    "TVë¶€_ìš”ê¸ˆì œ":     r"TV\s*\(ë¶€\)[\s\S]*?ìš”ê¸ˆì œ[:\s]*([^\n]+)",
    "TVë¶€_ì•½ì •ì‹œì‘":   r"TV\s*\(ë¶€\)[\s\S]*?ì•½ì •ê¸°ê°„[^(]*\((\d{4}-\d{2}-\d{2})\)",
    "TVë¶€_ì•½ì •ì¢…ë£Œ":   r"TV\s*\(ë¶€\)[\s\S]*?ì•½ì •ê¸°ê°„[^(]*\(\d{4}-\d{2}-\d{2}~(\d{4}-\d{2}-\d{2})\)",
    "TVë¶€_ë‹¨ë§":     r"TV\s*\(ë¶€\)[\s\S]*?ë‹¨ë§[:\s]*([^\n]+)",

    "U+ ìŠ¤ë§ˆíŠ¸í™ˆ":    r"U\+\s*ìŠ¤ë§ˆíŠ¸í™ˆ[:\s]*([0-9]+)",
    "ìŠ¤ë§ˆíŠ¸í™ˆ_ìš”ê¸ˆì œ":  r"ìŠ¤ë§ˆíŠ¸í™ˆ[\s\S]*?ìš”ê¸ˆì œ[:\s]*([^\n]+)",
    "ìŠ¤ë§ˆíŠ¸í™ˆ_ì•½ì •ì‹œì‘":r"ìŠ¤ë§ˆíŠ¸í™ˆ[\s\S]*?ì•½ì •ê¸°ê°„[^(]*\((\d{4}-\d{2}-\d{2})\)",
    "ìŠ¤ë§ˆíŠ¸í™ˆ_ì•½ì •ì¢…ë£Œ":r"ìŠ¤ë§ˆíŠ¸í™ˆ[\s\S]*?ì•½ì •ê¸°ê°„[^(]*\(\d{4}-\d{2}-\d{2}~(\d{4}-\d{2}-\d{2})\)",
    "ìŠ¤ë§ˆíŠ¸í™ˆ_ë‹¨ë§":   r"ìŠ¤ë§ˆíŠ¸í™ˆ[\s\S]*?ë‹¨ë§[:\s]*([^\n]+)",

    "ê³ ê°í¬ë§ì¼":     r"ê³ ê°í¬ë§ì¼[:\s]*([0-9\-]+)"
}

def parse_others(text: str) -> dict:
    return {
        k: (m.group(1).strip() if (m := re.search(p, text)) else None)
        for k, p in OTHER_PATTERNS.items()
    }

# â”€â”€â”€ 5) ê³µìš©ë‹¨ë§(í•˜ë‹¨ 50%) ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_common_device(img: Image.Image) -> str:
    W, H = img.size
    crop = img.crop((0, H//2, W, H))
    txt  = ocr_google_vision(crop)
    m = re.search(r"WIFI\s*([^\n]+)", txt, re.IGNORECASE)
    return m.group(1).strip() if m else None

# â”€â”€â”€ 6) í‘¸í„° ì‹ ì²­ìëª… ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FOOTER_ROI = (0.00, 0.80, 1.00, 1.00)
def ocr_footer(img: Image.Image) -> str:
    W, H = img.size
    crop = img.crop((0, int(FOOTER_ROI[1]*H), W, H))
    return ocr_google_vision(crop)

def parse_footer_name(text: str) -> str:
    m = re.search(r"ì‹ ì²­ìëª…/?ì—°ë½ì²˜\s*([ê°€-í£]+)", text)
    return m.group(1).strip() if m else None

# â”€â”€â”€ 7) Streamlit UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="OCR ì¢…í•© ì¶”ì¶œ", layout="wide")
st.title("ğŸ“· OCR â†’ ì „ì²´Â·í•˜ë‹¨Â·í‘¸í„° ì˜ì—­ë³„ í•„ë“œ ì¶”ì¶œ â†’ ì—‘ì…€ ì €ì¥")

uploaded = st.file_uploader(
    "ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥)", 
    type=["jpg","jpeg","png"], 
    accept_multiple_files=True
)

if uploaded:
    rows, prog = [], st.progress(0)
    for i, f in enumerate(uploaded):
        img = Image.open(f).convert("RGB")
        try:
            full_txt = ocr_google_vision(img)

            # 1) í—¤ë”
            hdr = parse_header(full_txt)
            # 2) ê¸°íƒ€
            oth = parse_others(full_txt)
            # 3) ê³µìš©ë‹¨ë§
            com = extract_common_device(img)
            # 4) ì‹ ì²­ìëª…
            ftxt = ocr_footer(img)
            fname = parse_footer_name(ftxt)

            record = {
                **hdr,
                **oth,
                "ê³µìš©ë‹¨ë§": com,
                "ì‹ ì²­ìëª…": fname,
                "íŒŒì¼ëª…":   f.name
            }
        except Exception as e:
            record = {"íŒŒì¼ëª…": f.name, "ì˜¤ë¥˜": str(e)}

        rows.append(record)
        prog.progress((i+1)/len(uploaded))

    df = pd.DataFrame(rows)
    st.dataframe(df, use_container_width=True)

    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False)
    st.download_button(
        "ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=buf.getvalue(),
        file_name="ocr_all_fields.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
